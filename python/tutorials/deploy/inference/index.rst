Inference
=========

The following tutorials will help you learn how to deploy MXNet models for inference applications.

.. container:: cards

   .. card::
      :title: GluonCV Models in a C++ Inference Application
      :link: https://gluon-cv.mxnet.io/build/examples_deployment/cpp_inference.html

      An example application that works with an exported MXNet GluonCV YOLO model.

   .. card::
      :title: Inference with Quantized Models
      :link: https://gluon-cv.mxnet.io/build/examples_deployment/int8_inference.html

      How to use quantized GluonCV models for inference on Intel Xeon Processors to gain higher performance.
   ..
      PLACEHOLDER

      .. card::
         :title: Scala and Java
         :link: scala.html

         How to use MXNet models in a Scala or Java environment.

      .. card::
         :title: C++
         :link: cpp.html

         How to use MXNet models in a C++ environment.
      PLACEHOLDER
   ..

.. toctree::
   :hidden:
   :maxdepth: 0

   :glob:
